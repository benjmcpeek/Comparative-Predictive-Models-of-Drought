{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46a235f6-c799-4d1e-8b39-563841c253ba",
   "metadata": {},
   "source": [
    "# Part 5: Findings & Agency Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107df671-70f5-4309-afaa-6a9756d58180",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Notebook Summary\n",
    "\n",
    "This notebook summarizes and synthesizes the findings of the data scientist research team based on the three types of predictive machine learning models explored in the last three parts of this report. We will present key findings, limitations of each model, and the team's recommendations to the California State Water Resources Board in investing resources for future modeling and drought prevention. In this notebook, the reader will find:\n",
    "\n",
    "* Production Model 1 Findings & Recommendations\n",
    "* Production Model 2 Findings & Recommendations\n",
    "* Production Model 3 Findings & Recommendations\n",
    "* Conclusion & Future Directions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb87c3b-6995-41b1-8d79-55f24e37506b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Production Model 1 Findings & Recommendations\n",
    "\n",
    "#### Model Summary\n",
    "\n",
    "**RNN Models**\n",
    "- The best performing RNN model used the Fresno region dataset and had a time-frame of weeks. The improvement in our second model shows that having a smaller scope creates a better performance. Our second RNN model fixed the overfit issues with a MSE difference of 0.0034. The Fresno model (RMSE: 0.037) outperformed our baseline NaiveForecaster (RMSE: 0.052). The issue with both of these models is the relationship between our target and feature variables. Our target variable's variation can only be explained by 5% of our features of our best performing RNN model (week). This makes using these neural network models not very efficient because our features are not contributing seemingly at all. We will use sktime and stats models in the linear_ts_model.ipynb notebook because they don't rely on any feature variables.\n",
    "\n",
    "Target = 'Precipitation': inches\n",
    "\n",
    "**Sktime and Stats Models** \n",
    "\n",
    "The best performing forecasting model was a SARIMA model with the following attributes:\n",
    "\n",
    "* Seasonality = 12\n",
    "* Time-Frame = Months\n",
    "* Trends = None \n",
    "\n",
    "This model was evaluated based on the **RMSE** and scored **0.0389**, indicating this model's average error was the smallest. Although our improvements in our predictions are minimal, the average measure of precipitation per month is fractions of an inch. This means that any development will also be within fractions of an inch. \n",
    "  \n",
    "\n",
    "#### Model Assumptions & Limitations\n",
    "\n",
    "The reader will recall that with these particular models we accumulated mean averages of the region. This can make predictions difficult because they generalize regions. Predicting the precipitation of all of California can be uninformative because different regions in California can have drastically different precipitation levels. We shrunk our scope to the city of Fresno which improved our models however the dataset was still displayed in mean averages. Due to this limitation, any recommendation must consider the broadness of the predictions\n",
    "\n",
    "#### Model Findings & Recommendations\n",
    "\n",
    "Here we can summarize our model findings and recommendations to the California State Water Resources Board.\n",
    "\n",
    "---\n",
    "\n",
    "**Finding 1**: Our model shows that we can predict the precipitation levels for up to 5 months into the future with an average error of 0.0395 inches.\n",
    "\n",
    "**Recommendation 1**: Based on this finding, the team recommends that the agency should consider using an SARIMA model with this easier accessible data for a cheaper method to forecast precipitation. Although models that use extensive data can have a smaller RMSE score this method can provide a faster and cheaper prediction.    \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b143d66a-6df5-462f-9c79-4f377445a6cb",
   "metadata": {},
   "source": [
    "## Production Model 2 Findings & Recommendations\n",
    "\n",
    "---\n",
    "\n",
    "#### Model Summary\n",
    "\n",
    "The reader will recall from Part 3 that our best-performing final production model was our **binary image classification convolutional neural network** with the following attributes:\n",
    "\n",
    "* Input Layer of 16 Nodes\n",
    "* Two Hidden Layers of 64 and 128 Nodes\n",
    "* Early Stopping with a Patience of 5 Epochs\n",
    "* Two Dropout Layers of 10% and 25%\n",
    "\n",
    "This production model was evaluated based on the **accuracy metric** and scored **0.95** on the test dataset, indicating a very high performing model.\n",
    "\n",
    "#### Model Assumptions & Limitations\n",
    "\n",
    "The reader will recall that with this particular model we assumed that wildfire image data serves as a suitable proxy for similarly dry landscapes either experiencing or on the cusp of experiencing drought conditions. The reader wil also recall that the dataset had a mixture of images with both the built and natural environment, particularly in the no wildire dataset, which may or may not have an impact on how the CNN is interpreting the different image classes. Due to these limitation, any recommendation must consider that:\n",
    "\n",
    "* A model trained on labeled drought image data might make more sense for future application of a CNN model.\n",
    "* An image dataset which excludes built environments might make more sense to test the accuracy of future models.\n",
    "\n",
    "#### Model Findings & Recommendations\n",
    "\n",
    "Here, we summarize our model findings and recommendations to the California State Water Resources Board.\n",
    "\n",
    "---\n",
    "\n",
    "**Finding 1**: Our EDA shows that there may be significant difference in the brightness and saturation of wildfire in comparison to no wildfire images and that these brightness differences appear to hold at much lower resolutions than the original image.\n",
    "\n",
    "**Recommendation 1**: Based on this finding, the team recommends that the agency could use NASA satellite images to scan for brightness in images without compromising the integrity of the predictive model.\n",
    "\n",
    "---\n",
    "\n",
    "**Finding 2**: Our model shows that we can predict wildifre areas from satellite images with approximately 95% accuracy.\n",
    "\n",
    "**Recommendation 2**: Based on this finding, the team recommends that the agency should invest in more modeling with satellite images with an emphasis on gathering labled drought severity images to train future models. Given the high success of this CNN model for wildfires, a CNN multi-classification image model for drought could be developed not just to predict drought or no drought but potentially the six different levels of drought severity according to the U.S. Drought Monitor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4235644-04a4-42a0-8dc9-0905c8529252",
   "metadata": {},
   "source": [
    "## Production Model 3 Findings & Recommendations\n",
    "\n",
    "---\n",
    "\n",
    "#### Model Summary\n",
    "\n",
    "The reader will recall from Part 4 that our best-performing final production model was...\n",
    "with the following attributes:\n",
    "\n",
    "* attribute 1\n",
    "* att 2\n",
    "* att 3\n",
    "\n",
    "This model was evaluated based on the **blah blah metric** and scored **super awesome number here**, indicating ...\n",
    "\n",
    "#### Model Assumptions & Limitations\n",
    "\n",
    "The reader will recall that with this particular model we assumed ... **something terrible which makes the model no good**. Due to this limitation, any recommendation must consider **the following super obvious thing**.\n",
    "\n",
    "#### Model Findings & Recommendations\n",
    "\n",
    "Here we can summarize our model findings and recommendations to the California State Water Resources Board.\n",
    "\n",
    "---\n",
    "\n",
    "**Finding 1**: Our model shows that..... **awesome finding WHOA**\n",
    "\n",
    "**Recommendation 1**: Based on this finding, the team recommends that the agency should ... **obviously do this thing**.\n",
    "\n",
    "---\n",
    "\n",
    "**Finding 2**: Our model shows that..... **awesome finding WHOA**\n",
    "\n",
    "**Recommendation 2**: Based on this finding, the team recommends that the agency should ... **obviously do this thing**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a585b6a-68cd-4589-907a-56fb418e568e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusion & Future Directions\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
